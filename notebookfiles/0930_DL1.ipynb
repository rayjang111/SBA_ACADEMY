{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "독립적인 도메인이없다\n",
    "독립적인 funding을 못받는다\n",
    "그래서 머신러닝하는 교수가 없다\n",
    "\n",
    "블랙박스 모델 작동성능확인=> 설명가능한 모델에서 성능 확인\n",
    "블랙박스 모델은 overfitting이 전제\n",
    "\n",
    "이 바닦에서 살아남는 사람 내 상황에 맞게 알고리즘을 수정하고 모델링을 할 수 있어야한다. \n",
    "\n",
    "데이터 전처리는 heuristic 베이스\n",
    "\n",
    "데이터만 가지고 있으면 모델을 짜겠다고 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 개요\n",
    "=> 모델의 자유도가 높다\n",
    "=> 모델조정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.constant(3)\n",
    "b=tf.constant(4)\n",
    "c=tf.pow(a,2)\n",
    "d=tf.multiply(a,b)\n",
    "e=tf.add(c,d) ###연산그래프 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 객체는 텐서플로 API의 일부로 파이썬 객체와 데이터, 객체의 메모리가 할당되어 있는 실행 환경 사이를 연결하며, 중간결과를 저장하고 최종결과를 작업 환경으로 보내준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs=21\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session() ###세션열기\n",
    "outs=sess.run(e)\n",
    "print(\"outs={}\".format(outs))\n",
    "sess.close() ###세션 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs=-2\n"
     ]
    }
   ],
   "source": [
    "###실습\n",
    "a=tf.constant(2)\n",
    "b=tf.constant(3)\n",
    "c=tf.pow(a,2)\n",
    "d=tf.multiply(a,b)\n",
    "e=tf.subtract(c,d)\n",
    "f=tf.div(c,d)\n",
    "g=tf.add(e,f)\n",
    "sess=tf.Session()\n",
    "outs=sess.run(g)\n",
    "print('outs={}'.format(outs))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x1382f908>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###텐서플로를 가져오면 기본 그래프가 자동으로 그려짐\n",
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###특정 노드의 실행을 요청하는 인수를 fetches 라고 함 \n",
    "### with 구문을 이용하여 세션을 열면 자동으로 세션이 닫힘\n",
    "###초기화 함수로는 truncated normal을 많이 쓴다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬곱\n",
    "행렬곱 연산을 위해 행과 열의 개수를 조절해 주어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3,)\n",
      "(3, 1)\n",
      "[[14]\n",
      " [32]]\n"
     ]
    }
   ],
   "source": [
    "x=tf.constant([[1,2,3],[4,5,6]])\n",
    "print(x.get_shape())\n",
    "a=tf.constant([1,2,3])\n",
    "print(a.get_shape())\n",
    "a=tf.expand_dims(a,1)\n",
    "print(a.get_shape())\n",
    "y=tf.matmul(x,a)\n",
    "sess=tf.InteractiveSession()\n",
    "print(y.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이름\n",
    "하나의 그래프 내에 동일한 이름을 가질 수 없음\n",
    "노드를 이름별로 계층적으로 그룹화 하는데 사용하는 함수 tf.scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수\n",
    "tf.Variable() 함수를 사용하여 변수를 만듬\n",
    "tf.global_variables_initializer()메서드를 이용하여 세션에서 초기화 연산 수행\n",
    "이 메서드는 변수에 메모리를 할당하고 초기값 설정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre run:\n",
      "<tf.Variable 'var:0' shape=(1, 5) dtype=float32_ref>\n",
      "\n",
      " post run \n",
      " [[-0.97474116  1.0839487  -1.3107207   2.5860794  -0.31215137]]\n"
     ]
    }
   ],
   "source": [
    "init_val=tf.random_normal((1,5),0,1)\n",
    "var=tf.Variable(init_val,name='var')\n",
    "print('pre run:\\n{}'.format(var))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    post_var=sess.run(var)\n",
    "print('\\n post run \\n {}'.format(post_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 플레이스 홀더\n",
    "변수를 지정안하고 저장을 나중에 하고 싶을때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs=[array([[-0.47399962],\n",
      "       [ 3.0401926 ],\n",
      "       [-5.823333  ],\n",
      "       [ 0.29834378],\n",
      "       [-2.697294  ]], dtype=float32), 3.0401926]\n"
     ]
    }
   ],
   "source": [
    "x_data=np.random.randn(5,10)\n",
    "w_data=np.random.randn(10,1)\n",
    "with tf.Graph().as_default():\n",
    "    x=tf.placeholder(tf.float32,shape=(5,10))\n",
    "    w=tf.placeholder(tf.float32,shape=(10,1))\n",
    "    b=tf.fill((5,1),-1.)\n",
    "    xw=tf.matmul(x,w)\n",
    "    xwb=xw+b\n",
    "    s=tf.reduce_max(xwb) ### max 값 하나로 차원을 축소해라\n",
    "    with tf.Session() as sess:\n",
    "        outs=sess.run([xwb,s],feed_dict={x:x_data,w:w_data})\n",
    "print(\"outs={}\".format(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1787793400287367"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x14be3f98>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Graph().as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-59-93d8da72a918>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\edu\\venv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\edu\\venv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\edu\\venv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\edu\\venv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\edu\\venv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\edu\\venv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.7) D:\\Build\\OpenCV\\opencv-3.4.7\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-2b0bbedad9a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'digits.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m900\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY_INV\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.7) D:\\Build\\OpenCV\\opencv-3.4.7\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "src=cv2.imread('digits.jpg',1)\n",
    "src=cv2.resize(src,(32,32))\n",
    "src=src[:,20:900,1]\n",
    "ret,src=cv2.threshold(src,150,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "kernel=cv2.getStructuringElement(cv2.MORPH_RECT,ksize=(3,3))\n",
    "for i in range(10):\n",
    "    src=cv2.erode(src,kernel=kernel,iterations=1)\n",
    "    src=cv2.dilate(src,kernel=kernel,iterations=1)\n",
    "ret,labels,stats,centroids=cv2.connectedComponentsWithStats(src)\n",
    "stats=stats[(stats[:,3]<200) & (stats[:,2]*stats[:,3]>200) & (stats[:,2]*stats[:,3]<8000)]\n",
    "array=[]\n",
    "imsi=[]\n",
    "for i in range(120):\n",
    "    imsi.append(stats[i])\n",
    "    if (i+1)%10==0:\n",
    "        imsi=sorted(imsi,key=lambda x:x[0])\n",
    "        array.append(imsi)\n",
    "        imsi=[]\n",
    "gray=src.copy()\n",
    "src=cv2.cvtColor(src,cv2.COLOR_GRAY2BGR)\n",
    "count=0\n",
    "for i in array:\n",
    "    for j in i:\n",
    "        x,y,width,height,area=j\n",
    "        cv2.rectangle(src,(x,y),(x+width,y+height),(0,0,255),2)\n",
    "        name='./kNN/testPNGs/{0}_{1}.png'.format((count+1)%10,(count)//10)\n",
    "        img=gray[y:y+height,x:x+height]\n",
    "        img=cv2.resize(img,(32,32))\n",
    "        cv2.imwrite(name,img)\n",
    "        count+=1\n",
    "cv2.imshow('src',src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "path='./kNN/trainingDigits/'\n",
    "files=os.listdir(path)\n",
    "def load_img(path):\n",
    "    img=np.array(pd.read_csv(path,header=None))\n",
    "    src=[]\n",
    "    empty=[]\n",
    "    for i in img:\n",
    "        empty=list(i[0])\n",
    "        src.append(empty)\n",
    "    src=np.array(src,dtype=np.uint8)\n",
    "    src[src==1]=255\n",
    "    src=cv2.resize(src,(32,32))\n",
    "    src=src.reshape(-1)\n",
    "    return src\n",
    "def make_labels(files):\n",
    "    y=[]\n",
    "    for i in files:\n",
    "        for j in range(10):\n",
    "            if i[0]=='{0}'.format(j):\n",
    "                y.append(j)\n",
    "    return y\n",
    "images=[]\n",
    "for i in files:\n",
    "    images.append(load_img(path+i))\n",
    "X_train=np.array(images)\n",
    "y_train=np.array(make_labels(files))\n",
    "test_path='./kNN/testPNGs/'\n",
    "test_files=os.listdir(test_path)\n",
    "y_test=np.array(make_labels(test_files))\n",
    "X_test=[]\n",
    "for i in test_files:\n",
    "    img=cv2.imread(test_path+i,0)\n",
    "    img=img.flatten()\n",
    "    X_test.append(img)\n",
    "X_test=np.array(X_test)\n",
    "gaussianNB=GaussianNB()\n",
    "gaussianNB.fit(X_train,y_train)\n",
    "print(gaussianNB.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
